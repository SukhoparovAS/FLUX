import os
import torch
from diffusers import AutoPipelineForText2Image
from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training
from transformers import TrainingArguments, Trainer
from PIL import Image

# üîπ –ü—É—Ç–∏ –∫ –º–æ–¥–µ–ª—è–º
MODEL_PATH = "./models/flux-1"
DATASET_PATH = "./dataset"
TRAINED_MODEL_PATH = "./trained_model"

# üîπ –°—Å—ã–ª–∫–∞ –Ω–∞ –º–æ–¥–µ–ª—å Hugging Face
MODEL_HF = "black-forest-labs/FLUX.1-schnell"


# üîπ –§—É–Ω–∫—Ü–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞–ª–∏—á–∏—è –º–æ–¥–µ–ª–∏
def is_model_downloaded():
    return os.path.exists(MODEL_PATH)


# üîπ –§—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ –Ω–µ —Å–∫–∞—á–∞–Ω–∞)
def download_model():
    if not is_model_downloaded():
        print("‚ö° –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å FLUX AI...")
        os.system(f"huggingface-cli download {MODEL_HF} --local-dir {MODEL_PATH}")
        print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")


# üîπ –§—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –Ω–∞ 10 —Ñ–æ—Ç–æ
def train_model():
    print("üöÄ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∑–∞–≥—Ä—É–∑—á–∏–∫
    pipeline = AutoPipelineForText2Image.from_pretrained(MODEL_PATH)
    pipeline.to("cuda")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –ø–∞–ø–∫–∏
    if not os.path.exists(DATASET_PATH):
        print("‚ùå –û—à–∏–±–∫–∞: –ü–∞–ø–∫–∞ —Å —Ñ–æ—Ç–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        return

    images = [Image.open(os.path.join(DATASET_PATH, img)) for img in os.listdir(DATASET_PATH) if img.endswith((".jpg", ".png"))]

    if len(images) < 10:
        print("‚ùå –û—à–∏–±–∫–∞: –ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 10 —Ñ–æ—Ç–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è!")
        return

    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è LoRA
    lora_config = LoraConfig(
        r=8, lora_alpha=32, lora_dropout=0.05,
        target_modules=["crossattention", "to_q", "to_v"],
        bias="none",
        task_type="TEXT_TO_IMAGE_GENERATION"
    )

    model = get_peft_model(pipeline.unet, lora_config)
    model = prepare_model_for_kbit_training(model)

    training_args = TrainingArguments(
        output_dir=TRAINED_MODEL_PATH,
        per_device_train_batch_size=1,
        num_train_epochs=5,
        save_strategy="epoch",
        logging_dir="logs"
    )

    trainer = Trainer(model=model, args=training_args, train_dataset=images)
    trainer.train()

    model.save_pretrained(TRAINED_MODEL_PATH)
    print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")


# üîπ –§—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
def generate_image():
    if not os.path.exists(TRAINED_MODEL_PATH):
        print("‚ùå –û—à–∏–±–∫–∞: –ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞! –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ.")
        return

    print("‚ö° –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å...")
    pipeline = AutoPipelineForText2Image.from_pretrained(TRAINED_MODEL_PATH)
    pipeline.to("cuda")

    prompt = input("–í–≤–µ–¥–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: ")
    print("üé® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
    
    image = pipeline(prompt).images[0]
    image.save("generated_image.png")
    
    print("‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: generated_image.png")


# üîπ –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é
def main():
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    download_model()

    print("\n–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:")
    print("1 - –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å")
    print("2 - –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
    
    choice = input("–í–∞—à –≤—ã–±–æ—Ä: ")
    if choice == "1":
        train_model()
    elif choice == "2":
        generate_image()
    else:
        print("‚ùå –û—à–∏–±–∫–∞: –ù–µ–≤–µ—Ä–Ω—ã–π –≤–≤–æ–¥!")


# üîπ –ó–∞–ø—É—Å–∫ –ø—Ä–æ–≥—Ä–∞–º–º—ã
if __name__ == "__main__":
    main()
